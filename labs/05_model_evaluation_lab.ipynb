{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DAT19 Class 5 - Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation with KNN\n",
    "\n",
    "Part of the big step with this lab is understanding general sklearn syntax. Each family of classification algorithms have various knobs and levers to tune it appropriately but there is a general overall structure to these models that will help you as you move forward.\n",
    "1. All models need to be trained. Sklearn models have a `.fit` method for doing so.\n",
    "2. We need to use the model to make a guess. the `.predict` method takes data and returns the model's guess for the value. Stipulations around this pertain to the specific model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time, we imported our data from the UCI Machine Learning repository using pandas. Scikit-learn also includes some well-known datasets. So, for convenience, we will import the iris data set from sklearn this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from the datasets load the iris data into a variable called iris\n",
    "from sklearn import datasets\n",
    "\n",
    "sk_iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(sk_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sk_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(sk_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's interesting:\n",
    "```Container object for datasets: dictionary-like object that exposes its keys as attributes.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sk_iris['DESCR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sk_iris['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sk_iris['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Remember last time when we put all the features in a matrix and the labels (what we are trying to predict) into a vector?\n",
    "\n",
    "Let's re-assign the data to standard named variables. Sklearn makes this very easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = sk_iris.data #features\n",
    "y = sk_iris.target #class labels\n",
    "Names = sk_iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(X)\n",
    "print np.shape(X)\n",
    "print X\n",
    "## features now in a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(Names)\n",
    "print np.shape(y)\n",
    "print Names\n",
    "\n",
    "# matrix of features, vector of class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we get into cross validation! The first step is to split the data into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# is there a function to do that in sklearn?\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = range(150) #What data structure is ind? What is its shape?\n",
    "## list with values from 0-149\n",
    "\n",
    "np.random.shuffle(ind) #Why must we randomly shuffle the (indices for the) training data before splitting it?\n",
    "## shuffling because classes are in order; if we don't shuffle we won't get folds that represent dataset as a whole\n",
    "\n",
    "test_ind = ind[:150/5] #Would this work if 20% of the number of records were not an integer?\n",
    "## grab beginning of list 150/5 because we're using 1/5 of entire set\n",
    "\n",
    "train_ind = ind[150/5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print test_ind\n",
    "print 'length of test index is ' + str(len(test_ind))\n",
    "print '\\n'\n",
    "print train_ind\n",
    "print 'length of training index is ' + str(len(train_ind))\n",
    "\n",
    "## example of train/test split!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Another example of train/test split\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "\n",
    "## for each index in list grab data that fits criteria and append to list\n",
    "for ind in test_ind:\n",
    "    X_test.append(X[ind])\n",
    "    y_test.append(y[ind])\n",
    "    \n",
    "for ind in train_ind:\n",
    "    X_train.append(X[ind])\n",
    "    y_train.append(y[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=0)\n",
    "\n",
    "## test_size = size of fold\n",
    "## we're assigning results to multiple variables\n",
    "## this function is able to give back list to be unpacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait a minute, what's going on with this syntax above? Does anything about it look unusual to you?\n",
    "Let's take a look at the [function documentation](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html) and the [user guide](http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tts_return = train_test_split( X, y, test_size=0.20, random_state=0)\n",
    "print len(tts_return)\n",
    "print type(tts_return)\n",
    "#tts_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print np.shape(X_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.shape(y_train)\n",
    "y_train\n",
    "# data below corresponds with features above\n",
    "# the first row above corresponds with the first index below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Quick Question: How can we double check that got the number of features and labels that we expected?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll train our model and use it to make predictions, following the steps we outlined last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train KNN classifier defined function on the train data\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myknn = KNeighborsClassifier(2).fit(X_train,y_train)\n",
    "## want 2 neighbors in model\n",
    "## fit it using the training data and training data from test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's figure out how good our model is. The traditional score is what percentage of my labels did I correctly identify. This is called **accuracy** or **precision**. There are other types of statistical scores but we will start here. We'll ask our model to predict what the labels for our test set are, then generate a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## predict feeds in data and gets predictions out\n",
    "predictions = myknn.predict(X_test)\n",
    "print predictions\n",
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "\n",
    "for a,b in zip(y_test,myknn.predict(X_test)):\n",
    "    if a == b:\n",
    "        correct += 1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print \"Number correct:\",correct\n",
    "print \"Score:\",float(correct)/len(y_test)\n",
    "\n",
    "\n",
    "### this is only 1 sample of OOS test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was easy enough. Sklearn also has an easy method for generating a score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myknn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn also has a way of showing more information about the prediction. Here, we're using sklearn.metrics.classification_report to generate a more informative picture. The wikipedia pages for recall, f1-score, and support are also informative if you're looking to understand more.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print metrics.classification_report([sk_iris['target_names'][label] for label in y_test], \n",
    "                                    [sk_iris['target_names'][label] for label in myknn.predict(X_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "#### 1. How does the model perform as we increase the number of neighbors?  To answer this, plot the score as a function of the number of neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of the various numbers of neighbors to use to build models\n",
    "# Create training and test sets\n",
    "# Iterate through that list and for each number of neighbors:\n",
    "#    Build a KNN model\n",
    "#    Evaluate it\n",
    "#    Record the score with the number of neighbors for that model\n",
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sk_iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = sk_iris.data #features\n",
    "y = sk_iris.target #class labels\n",
    "Names = sk_iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = range(150) \n",
    "\n",
    "np.random.shuffle(ind)\n",
    "\n",
    "test_ind = ind[:150/5] \n",
    "\n",
    "train_ind = ind[150/5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a list of the various numbers of neighbors to use to build models\n",
    "# Create training and test sets\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "\n",
    "## for each index in list grab data that fits criteria and append to list\n",
    "for ind in test_ind:\n",
    "    X_test.append(X[ind])\n",
    "    y_test.append(y[ind])\n",
    "    \n",
    "for ind in train_ind:\n",
    "    X_train.append(X[ind])\n",
    "    y_train.append(y[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 5.6,  3. ,  4.1,  1.3]), array([ 7.7,  3.8,  6.7,  2.2]), array([ 6.4,  3.1,  5.5,  1.8]), array([ 6.4,  2.7,  5.3,  1.9]), array([ 7.3,  2.9,  6.3,  1.8]), array([ 6.5,  3. ,  5.8,  2.2]), array([ 5. ,  3.2,  1.2,  0.2]), array([ 6.3,  2.3,  4.4,  1.3]), array([ 4.4,  3. ,  1.3,  0.2]), array([ 5.7,  2.9,  4.2,  1.3]), array([ 6.7,  3.1,  4.7,  1.5]), array([ 5.6,  3. ,  4.5,  1.5]), array([ 6.3,  2.5,  4.9,  1.5]), array([ 6. ,  3. ,  4.8,  1.8]), array([ 6.1,  2.8,  4. ,  1.3]), array([ 6.1,  2.6,  5.6,  1.4]), array([ 5.8,  2.7,  4.1,  1. ]), array([ 4.9,  3.1,  1.5,  0.1]), array([ 4.8,  3. ,  1.4,  0.3]), array([ 4.9,  3.1,  1.5,  0.1]), array([ 5.4,  3.4,  1.5,  0.4]), array([ 4.8,  3.4,  1.9,  0.2]), array([ 4.9,  3. ,  1.4,  0.2]), array([ 7.4,  2.8,  6.1,  1.9]), array([ 6.3,  3.4,  5.6,  2.4]), array([ 5.9,  3.2,  4.8,  1.8]), array([ 5.8,  2.6,  4. ,  1.2]), array([ 5.8,  4. ,  1.2,  0.2]), array([ 4.6,  3.4,  1.4,  0.3]), array([ 5.5,  2.3,  4. ,  1.3])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print X_test\n",
    "np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 2, 2, 2, 0, 1, 0, 1, 1, 1, 1, 2, 1, 2, 1, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 0, 0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print y_test\n",
    "np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 5.8,  2.7,  5.1,  1.9]), array([ 5. ,  2. ,  3.5,  1. ]), array([ 6.7,  3.3,  5.7,  2.5]), array([ 5.7,  2.8,  4.1,  1.3]), array([ 4.6,  3.6,  1. ,  0.2]), array([ 6.7,  2.5,  5.8,  1.8]), array([ 4.8,  3.4,  1.6,  0.2]), array([ 7.2,  3.6,  6.1,  2.5]), array([ 6. ,  2.2,  4. ,  1. ]), array([ 6.5,  3.2,  5.1,  2. ]), array([ 6.9,  3.1,  4.9,  1.5]), array([ 6. ,  2.7,  5.1,  1.6]), array([ 6.1,  3. ,  4.9,  1.8]), array([ 6.4,  2.8,  5.6,  2.2]), array([ 6.3,  3.3,  4.7,  1.6]), array([ 5.5,  2.4,  3.7,  1. ]), array([ 5. ,  3.6,  1.4,  0.2]), array([ 5.7,  4.4,  1.5,  0.4]), array([ 4.7,  3.2,  1.6,  0.2]), array([ 5.3,  3.7,  1.5,  0.2]), array([ 5.7,  2.6,  3.5,  1. ]), array([ 6.8,  3. ,  5.5,  2.1]), array([ 6.7,  3.1,  4.4,  1.4]), array([ 7.1,  3. ,  5.9,  2.1]), array([ 6.1,  2.8,  4.7,  1.2]), array([ 5.1,  3.3,  1.7,  0.5]), array([ 5.4,  3.9,  1.3,  0.4]), array([ 5.4,  3. ,  4.5,  1.5]), array([ 5. ,  3.5,  1.6,  0.6]), array([ 5.8,  2.8,  5.1,  2.4]), array([ 6.8,  3.2,  5.9,  2.3]), array([ 5.6,  2.5,  3.9,  1.1]), array([ 5.4,  3.4,  1.7,  0.2]), array([ 4.6,  3.1,  1.5,  0.2]), array([ 5.5,  2.5,  4. ,  1.3]), array([ 5.1,  3.5,  1.4,  0.3]), array([ 5.6,  2.7,  4.2,  1.3]), array([ 5.9,  3. ,  4.2,  1.5]), array([ 7.6,  3. ,  6.6,  2.1]), array([ 6.3,  2.8,  5.1,  1.5]), array([ 5.1,  3.8,  1.9,  0.4]), array([ 5.5,  3.5,  1.3,  0.2]), array([ 4.6,  3.2,  1.4,  0.2]), array([ 4.9,  2.5,  4.5,  1.7]), array([ 4.9,  2.4,  3.3,  1. ]), array([ 5.5,  2.6,  4.4,  1.2]), array([ 6.8,  2.8,  4.8,  1.4]), array([ 6.3,  2.7,  4.9,  1.8]), array([ 5.2,  3.4,  1.4,  0.2]), array([ 5.1,  3.4,  1.5,  0.2]), array([ 5.5,  4.2,  1.4,  0.2]), array([ 4.7,  3.2,  1.3,  0.2]), array([ 6.9,  3.2,  5.7,  2.3]), array([ 6.9,  3.1,  5.4,  2.1]), array([ 5. ,  3.3,  1.4,  0.2]), array([ 6.7,  3. ,  5. ,  1.7]), array([ 4.8,  3. ,  1.4,  0.1]), array([ 6.2,  2.9,  4.3,  1.3]), array([ 5.4,  3.9,  1.7,  0.4]), array([ 6.2,  3.4,  5.4,  2.3]), array([ 6. ,  3.4,  4.5,  1.6]), array([ 6.7,  3. ,  5.2,  2.3]), array([ 4.8,  3.1,  1.6,  0.2]), array([ 7.2,  3. ,  5.8,  1.6]), array([ 6.4,  3.2,  4.5,  1.5]), array([ 4.5,  2.3,  1.3,  0.3]), array([ 6.5,  3. ,  5.2,  2. ]), array([ 7.7,  3. ,  6.1,  2.3]), array([ 5.8,  2.7,  5.1,  1.9]), array([ 5. ,  3. ,  1.6,  0.2]), array([ 4.9,  3.1,  1.5,  0.1]), array([ 4.4,  3.2,  1.3,  0.2]), array([ 5.1,  3.8,  1.6,  0.2]), array([ 6.4,  2.8,  5.6,  2.1]), array([ 6.2,  2.2,  4.5,  1.5]), array([ 6.6,  3. ,  4.4,  1.4]), array([ 5.6,  2.9,  3.6,  1.3]), array([ 6. ,  2.9,  4.5,  1.5]), array([ 5.1,  3.7,  1.5,  0.4]), array([ 4.4,  2.9,  1.4,  0.2]), array([ 7.9,  3.8,  6.4,  2. ]), array([ 7.7,  2.6,  6.9,  2.3]), array([ 5.1,  3.5,  1.4,  0.2]), array([ 5.2,  4.1,  1.5,  0.1]), array([ 6.4,  2.9,  4.3,  1.3]), array([ 6.1,  3. ,  4.6,  1.4]), array([ 6.3,  2.5,  5. ,  1.9]), array([ 5.2,  3.5,  1.5,  0.2]), array([ 5. ,  3.4,  1.5,  0.2]), array([ 5.9,  3. ,  5.1,  1.8]), array([ 6.6,  2.9,  4.6,  1.3]), array([ 5.7,  3. ,  4.2,  1.2]), array([ 6.7,  3.3,  5.7,  2.1]), array([ 5.5,  2.4,  3.8,  1.1]), array([ 7.2,  3.2,  6. ,  1.8]), array([ 5.2,  2.7,  3.9,  1.4]), array([ 5.7,  2.5,  5. ,  2. ]), array([ 6.3,  3.3,  6. ,  2.5]), array([ 5. ,  3.5,  1.3,  0.3]), array([ 5.1,  3.8,  1.5,  0.3]), array([ 6.3,  2.9,  5.6,  1.8]), array([ 5.7,  2.8,  4.5,  1.3]), array([ 4.3,  3. ,  1.1,  0.1]), array([ 6.5,  2.8,  4.6,  1.5]), array([ 6.7,  3.1,  5.6,  2.4]), array([ 5.7,  3.8,  1.7,  0.3]), array([ 6.2,  2.8,  4.8,  1.8]), array([ 5.1,  2.5,  3. ,  1.1]), array([ 5.6,  2.8,  4.9,  2. ]), array([ 5. ,  2.3,  3.3,  1. ]), array([ 5.4,  3.7,  1.5,  0.2]), array([ 6.5,  3. ,  5.5,  1.8]), array([ 7. ,  3.2,  4.7,  1.4]), array([ 7.7,  2.8,  6.7,  2. ]), array([ 6.4,  3.2,  5.3,  2.3]), array([ 5. ,  3.4,  1.6,  0.4]), array([ 6. ,  2.2,  5. ,  1.5]), array([ 5.8,  2.7,  3.9,  1.2]), array([ 6.9,  3.1,  5.1,  2.3]), array([ 6.1,  2.9,  4.7,  1.4])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print X_train\n",
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 2, 1, 0, 2, 0, 2, 1, 2, 1, 1, 2, 2, 1, 1, 0, 0, 0, 0, 1, 2, 1, 2, 1, 0, 0, 1, 0, 2, 2, 1, 0, 0, 1, 0, 1, 1, 2, 2, 0, 0, 0, 2, 1, 1, 1, 2, 0, 0, 0, 0, 2, 2, 0, 1, 0, 1, 0, 2, 1, 2, 0, 2, 1, 0, 2, 2, 2, 0, 0, 0, 0, 2, 1, 1, 1, 1, 0, 0, 2, 2, 0, 0, 1, 1, 2, 0, 0, 2, 1, 1, 2, 1, 2, 1, 2, 2, 0, 0, 2, 1, 0, 1, 2, 0, 2, 1, 2, 1, 0, 2, 1, 2, 2, 0, 2, 1, 2, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print y_train\n",
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myknn = KNeighborsClassifier(11).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 2 2 2 0 1 0 1 1 1 1 2 1 2 1 0 0 0 0 0 0 2 2 2 1 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = myknn.predict(X_test)\n",
    "print predictions\n",
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number correct: 29\n",
      "Score: 0.966666666667\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "for tumble,weed in zip(y_test,myknn.predict(X_test)):\n",
    "    if tumble == weed:\n",
    "        correct += 1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print \"Number correct:\",correct\n",
    "print \"Score:\",float(correct)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Do different train/test splits affect our score (accuracy)? How much do the scores vary each time you shuffle and split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Yes, different train/test splits affect score (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Using same dataset, different test/train percentage splits ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sk_iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = sk_iris.data #features\n",
    "y = sk_iris.target #class labels\n",
    "Names = sk_iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = range(150) \n",
    "\n",
    "np.random.shuffle(ind)\n",
    "\n",
    "test_ind = ind[:150/5] \n",
    "\n",
    "train_ind = ind[150/5:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
